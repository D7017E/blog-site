---
layout: post
title:  "Week 42: Sprint 1"
date:   2022-10-18 13:00:00 +0200
published: true
---


## Block programming
### Block server
We have in, Pepper connection part, implemented head gestures, eye gestures, text-to-speech, and also translation gestures. The implementation follow the UML diagram that we did during the last sprint. 

The methods for moving is pretty general where you can define how fast you want to move pepper in every direction, such as x, y and rotation. 

The head gestures is too pretty general but you can only define one direction at a time. You can however call the function twice to get the head moving up and to the right at the same time. But the function itself can only do one thing at a time. There is also functions for shake and nod head.

The text-to-speech is simple, only send the text to Pepper so that it later can say the input text.

The expressions with the eyes is quite done, we haven't implemented any functionality for ear and shoulder expressions yet. Those expressions that exists are 
- rotate eyes, which makes a color rotate around the eyes.
- fade eyes, which fades the eyes color to another color
- angry eyes, which makes part of the eyes red and the upper part black
- sad eyes, which makes the eyes blue
- blink eyes, which makes the eyes blink
- squint eyes, which makes the eyes squint for a duration of time
- random eyes, which makes the eyes go random color for a duration of time
- wink eye, which makes one eye wink

What we have left to do is arm and hand gestures, we also need to implement a way to retrieve data from the blockly side.

### Blockly
The issues with generating python2.7 code with the build in codegenerator in Blockly are now resolved. Furthermore, the ability to send the generated code to the Block server through HTTP is added. Blocks for each of the expressions mentioned above in **Block server** have been implemented. 

There was also a dependency issue with the NPM package of Blockly and some extensions used for creating prettier blocks. This was resolved with changing the version of some of the packages so the Blockly site works as intended again. 

In the upcoming sprint, we will focus on adding all the basic syntax blocks from Blocklys library to the toolbox (the part of the Blockly editor where all available blocks are). Because of the fact that the target group is almost only Swedish speaking children with very limited English knowledge we will translate all blocks to Swedish from English which it is right know. It could be smart to have the option to choose between Swedish and English in which case both implementations is nedded.

Lastly, we will keep adding new blocks as the **Block server** group defines more functionalities.

## Web interaction

## Rock-paper-scissors

During this sprint we have managed to show images on Pepper’s tablet and also together with members of the Blockly group have found how to open up the settings menu on Pepper’s tablet. This menu is android based and can change settings such as screen brightness and network connection for the tablet. In addition, we also made documentation on how to open these settings. 

The main thing we focused on this sprint was that Pepper should be able to take pictures, which we managed to do. However in order to get meaningful pictures that can be sent to the image recognition software, we would need to add support for recognizing and tracking hands of the current player which we have started to look into and will work more on in the next sprint.

We have also installed a linter and formatter for Pep8 which the entire team decided should be standard in the project. 


## Image recognition
